"""
ë¬¸ì„œ ì²­í¬ ë¶„í•  ëª¨ë“ˆ
-------------------
ê¸´ ë¬¸ì„œë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ ì„ë² ë”© íš¨ìœ¨ì„ ë†’ì¸ë‹¤.
"""

from langchain.text_splitter import RecursiveCharacterTextSplitter
from utils.logger import setup_logger

logger = setup_logger()


def split_documents(
    documents: list[dict], chunk_size: int = 500, chunk_overlap: int = 50
) -> list[str]:
    """
    ê¸´ í…ìŠ¤íŠ¸ ë¬¸ì„œë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í• í•œë‹¤.
    Args:
        documents (list[dict]): {"title": str, "content": str, "repo_id": int}
        chunk_size (int): ì²­í¬ì˜ ìµœëŒ€ ê¸¸ì´
        chunk_overlap (int): ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” ê¸¸ì´
    Returns:
        list[dict]: {"text": str, "repo_id": int, "title": str}
    """
    if not documents:
        logger.warning("âš ï¸ ë¶„í• í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return []

    splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        separators=["\n\n", "\n", ".", " "],
    )

    chunks = []
    for doc in documents:
        content = doc.get("content", "")
        repo_id = doc.get("repo_id")
        title = doc.get("title", "unknown")

        if not content.strip():
            continue

        split_texts = splitter.split_text(content)
        for i, chunk_text in enumerate(split_texts):
            chunks.append(
                {"text": chunk_text, "repo_id": repo_id, "title": f"{title}_part{i+1}"}
            )

    logger.info(
        f"ğŸ“š ì²­í¬ ë¶„í•  ì™„ë£Œ: {len(chunks)}ê°œ (chunk_size={chunk_size}, overlap={chunk_overlap})"
    )
    return chunks
